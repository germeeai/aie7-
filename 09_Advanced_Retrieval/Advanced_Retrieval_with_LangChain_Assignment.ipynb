{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- 🤝 Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- 🤝 Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# 🤝 Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using our Loan Data once again - this time the strutured data available through the CSV!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "loader = CSVLoader(\n",
        "    file_path=f\"./data/complaints.csv\",\n",
        "    metadata_columns=[\n",
        "      \"Date received\", \n",
        "      \"Product\", \n",
        "      \"Sub-product\", \n",
        "      \"Issue\", \n",
        "      \"Sub-issue\", \n",
        "      \"Consumer complaint narrative\", \n",
        "      \"Company public response\", \n",
        "      \"Company\", \n",
        "      \"State\", \n",
        "      \"ZIP code\", \n",
        "      \"Tags\", \n",
        "      \"Consumer consent provided?\", \n",
        "      \"Submitted via\", \n",
        "      \"Date sent to company\", \n",
        "      \"Company response to consumer\", \n",
        "      \"Timely response?\", \n",
        "      \"Consumer disputed?\", \n",
        "      \"Complaint ID\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "loan_complaint_data = loader.load()\n",
        "\n",
        "for doc in loan_complaint_data:\n",
        "    doc.page_content = doc.metadata[\"Consumer complaint narrative\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': './data/complaints.csv', 'row': 0, 'Date received': '03/27/25', 'Product': 'Student loan', 'Sub-product': 'Federal student loan servicing', 'Issue': 'Dealing with your lender or servicer', 'Sub-issue': 'Trouble with how payments are being handled', 'Consumer complaint narrative': \"The federal student loan COVID-19 forbearance program ended in XX/XX/XXXX. However, payments were not re-amortized on my federal student loans currently serviced by Nelnet until very recently. The new payment amount that is effective starting with the XX/XX/XXXX payment will nearly double my payment from {$180.00} per month to {$360.00} per month. I'm fortunate that my current financial position allows me to be able to handle the increased payment amount, but I am sure there are likely many borrowers who are not in the same position. The re-amortization should have occurred once the forbearance ended to reduce the impact to borrowers.\", 'Company public response': 'None', 'Company': 'Nelnet, Inc.', 'State': 'IL', 'ZIP code': '60030', 'Tags': 'None', 'Consumer consent provided?': 'Consent provided', 'Submitted via': 'Web', 'Date sent to company': '03/27/25', 'Company response to consumer': 'Closed with explanation', 'Timely response?': 'Yes', 'Consumer disputed?': 'N/A', 'Complaint ID': '12686613'}, page_content=\"The federal student loan COVID-19 forbearance program ended in XX/XX/XXXX. However, payments were not re-amortized on my federal student loans currently serviced by Nelnet until very recently. The new payment amount that is effective starting with the XX/XX/XXXX payment will nearly double my payment from {$180.00} per month to {$360.00} per month. I'm fortunate that my current financial position allows me to be able to handle the increased payment amount, but I am sure there are likely many borrowers who are not in the same position. The re-amortization should have occurred once the forbearance ended to reduce the impact to borrowers.\")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loan_complaint_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"LoanComplaints\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    loan_complaint_data,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"LoanComplaints\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, the most common issues with loans appear to involve mismanagement and errors by servicers, including:\\n\\n- Errors in loan balances and balances growing despite payments\\n- Incorrect or inconsistent reporting of loan status (e.g., showing as delinquent when current)\\n- Difficulty applying payments correctly or paying off loans faster\\n- Disputes over interest rates, fees, and loan terms\\n- Unauthorized loan transfers and lack of communication about such transfers\\n- Mishandling of loan data, including privacy violations\\n- Challenges in getting accurate information about loans and repayment terms\\n\\nWhile multiple issues are reported, the most frequent theme is problems related to servicing errors, misreported information, and lack of transparency in handling loans.'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, yes, some complaints were not handled in a timely manner. Specifically, there are complaints where the response status indicates \"No\" for timely response. For example:\\n\\n- Complaint ID 12709087 (submitted on 03/28/25 by MOHELA) was marked as \"Timely response? No.\"\\n- Complaint ID 12973003 (submitted on 04/14/25 by EdFinancial Services) was marked as \"Timely response? Yes,\" so this one was handled timely.\\n- Complaint ID 13062402 (submitted on 04/18/25 by Nelnet, Inc.) was \"Timely response? Yes.\"\\n- Complaint ID 12832400 (submitted on 04/05/25 by Maximus Federal Services) was \"Timely response? Yes.\"\\n- Complaint ID 12975634 (submitted on 04/14/25 by Maximus Federal Services) was \"Timely response? Yes.\"\\n\\nTherefore, at least one complaint (ID 12709087) was not handled in a timely manner.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People failed to pay back their loans mainly due to a combination of factors such as:\\n\\n1. **Accumulation of interest during forbearance or deferment:** Many borrowers had limited options besides forbearance or deferment, which allowed interest to continue accruing, increasing the total amount owed and making repayment more difficult once payments resumed.\\n\\n2. **Financial hardships and stagnant wages:** Some borrowers experienced financial difficulties, including unemployment, low income, high living expenses, or unexpected expenses like foreclosure or bankruptcy, which impaired their ability to make payments.\\n\\n3. **Lack of clear communication and information:** Several complaints highlighted a lack of notification or transparency from loan servicers regarding loan transfer dates, repayment deadlines, or changes in payment plans, leading borrowers to become delinquent unknowingly.\\n\\n4. **Difficulty in managing repayment plans:** Borrowers reported challenges in applying payments correctly, in accessing income-driven repayment plans, or in adjusting their repayment terms, which contributed to missed or late payments.\\n\\n5. **Mismanagement and misinformation:** Issues like incorrect reporting of delinquencies, unauthorized loan transfers, and inadequate disclosures about interest and repayment obligations caused confusion and hindered borrowers' ability to stay current.\\n\\n6. **Unmanageable loan balances despite payments:** Some borrowers indicated that despite making payments for years, their balances remained high or even increased due to high interest rates and the way payments were applied, leading to prolonged debt and difficulty in repayment.\\n\\nIn summary, difficulties in repayment often stemmed from systemic issues with loan management, limited supportive options, and borrowers' financial hardships, all compounded by insufficient communication and transparency from loan servicers.\""
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(loan_complaint_data, )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the provided complaints, is dealing with the lender or servicer, particularly issues related to the handling of payments, obtaining accurate information about loans, and disputes over fees or information. Specifically, common problems include trouble applying payments correctly, receiving incorrect or bad information about loan balances or terms, and issues with repayment practices that may be perceived as predatory.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, all the complaints in the context received a response from the companies, and each response is marked as \"Closed with explanation\" and noted as \"Timely response? Yes.\" This indicates that the complaints were handled in a timely manner. Therefore, there are no complaints in the provided data that were left unhandled or not handled in a timely manner.'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People often fail to pay back their loans due to a variety of reasons, including issues with their loan servicers and payment plans. For example, some complain about being unable to get proper assistance or corrections despite fulfilling requirements, as seen in cases where loan servicers steer borrowers into wrong types of forbearances or fail to communicate effectively. Others face problems such as payment reversals or billing errors, which can lead to missed payments and damage to credit scores. Additionally, some borrowers are not properly notified about changes in their loan status or repayment obligations, leading to unintentional overdue payments. All these factors contribute to difficulties in repayment and can result in failure to pay back loans.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse, if only we had a way to test this (SPOILERS: We do, the second half of the notebook will cover this)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ❓ Question #1:\n",
        "\n",
        "Give an example query where BM25 is better than embeddings and justify your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "****\n",
        "\n",
        "BM25 excels at exact keyword matching, so it’s more likely to retrieve documents that contain words that the query literally has"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-v3.5\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided data, the most common issue with loans appears to be problems related to dealing with lenders or servicers. Specifically, many complaints involve errors in loan information, mismanagement, lack of communication, incorrect balances, unauthorized transfers, and mishandling of personal data. These issues often result in confusion and disputes over loan balances, interest, and repayment obligations.'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the information provided, it appears that at least one complaint was not handled in a timely manner. Specifically, the complaint regarding the student loan account review and request for account adjustments has been ongoing for over 18 months with no resolution. Additionally, the complainant reports that they have not received a response despite multiple requests, indicating a delay exceeding a year in addressing their concerns.\\n\\nHowever, in the case of the complaint from EdFinancial Services about auto pay issues and unapplied payments, the response was marked as \"Closed with explanation\" and indicated that the response was timely.\\n\\nIn summary, yes, there was at least one complaint that did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans for several reasons, including:\\n\\n1. Lack of awareness or understanding: Many borrowers, especially first-generation college students, were not informed about the requirement to repay loans and did not realize they had to pay back the borrowed amounts.\\n\\n2. Administrative issues and miscommunication: Borrowers experienced problems such as being unaware of loan transfers between servicers, not receiving proper notifications about due payments or account updates, and having difficulty accessing their accounts due to incorrect information or technical issues.\\n\\n3. Accumulation of interest and repayment challenges: Borrowers faced ongoing interest accrual, especially when loans were deferred or put into forbearance, which extended the repayment period and increased the total amount owed. Some found it difficult to increase payments due to financial hardship, stagnant wages, or other financial obligations.\\n\\n4. Inadequate or confusing options for repayment: The available options, like forbearance or deferment, often led to increased interest, making it harder to pay down the principal. Borrowers felt that the options offered did not effectively address their financial realities.\\n\\n5. Economic hardships and job uncertainties: Many borrowers, particularly those without jobs that qualify for loan forgiveness programs, found themselves unable to make payments or pay off loans within a reasonable time due to limited income and economic challenges.\\n\\nOverall, a combination of lack of information, administrative issues, financial hardship, and the complex nature of loan repayment contributed to why people failed to pay back their loans.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the complaints provided, appears to be problems related to loan servicer misconduct. This includes errors in loan balances, misapplied payments, wrongful denials of payment plans, incorrect reporting of account status (such as delinquency or overdue status), improper handling of forbearance or deferment, and inadequate communication or notification about account changes or issues. Many complaints also involve confusion or inaccuracies about loan terms, interest calculations, and account transfer procedures, which contribute to financial hardship and credit problems for borrowers.'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, several complaints indicate that they were not handled in a timely manner. Specifically:\\n\\n- One complaint (Complaint ID: 12709087) regarding a loan application not being processed was marked \"No\" in timely response, with the complaint dating from late March 2025.\\n- Another complaint (Complaint ID: 12654977) about a payment status issue was marked \"No\" in timely response, with the complaint also from late March 2025.\\n- Multiple other complaints mention delays over various periods, with some persistent issues lasting several months and reactions from companies being delayed or insufficient.\\n\\nIn summary, yes, numerous complaints appear to have not been handled promptly, with at least two explicitly marked as \"not timely.\"'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People often failed to pay back their loans due to a variety of reasons highlighted in the complaints. Some common issues include:\\n\\n1. **Errors and Misreporting**: Incorrect account status updates, such as being reported as delinquent or in default when not truly in default, which adversely affected credit scores.\\n\\n2. **Lack of Proper Communication**: Borrowers were not adequately informed about their repayment status, loan transfer details, or the expiration of forbearance periods, leading to unintentional missed payments.\\n\\n3. **Servicer misconduct**: Practices such as \"forbearance steering,\" where borrowers were placed into long-term forbearance instead of being informed about income-driven repayment or rehabilitation options, resulted in accruing interest and ballooning balances.\\n\\n4. **Difficulty in Navigating Repayment Options**: Borrowers were often not provided with clear or sufficient guidance on available repayment plans or forgiveness programs, making it challenging to manage payments effectively.\\n\\n5. **Technical and Administrative Errors**: Missing payment history, incorrect reporting, or database errors led to inaccurate account statuses and default designations.\\n\\n6. **Financial Hardship and Unmanageable Repayment Conditions**: Borrowers facing economic difficulties, unemployment, or other hardships found it impossible to keep up with the payments, especially when interest kept accumulating or when options like deferment or forbearance extended repayment periods but increased overall debt.\\n\\n7. **Lack of Support and Poor Customer Service**: Inadequate assistance from loan servicers in managing repayment plans or correcting errors hindered borrowers’ ability to stay current on their loans.\\n\\nIn summary, failures to pay back loans were often driven by systemic issues involving miscommunication, administrative errors, and exploitative practices by servicers, coupled with borrowers’ financial hardships and lack of clear, accessible guidance on repayment options.'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ❓ Question #2:\n",
        "\n",
        "Explain how generating multiple reformulations of a user query can improve recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "****\n",
        "\n",
        "Captures synonyms and paraphrases\n",
        "\n",
        "Reformulations allow the retriever to explore different angles or interpretations of the question, reducing the risk of missing useful information\n",
        "Bypasses vocabulary mismatches: Users and documents often use different terminology\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = loan_complaint_data\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=750)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "\n",
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = QdrantVectorStore(\n",
        "    collection_name=\"full_documents\", embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the context provided, appears to be problems related to federal student loan servicing, including errors in loan balances, misapplied payments, wrongful denials of payment plans, and issues with inaccurate or misleading credit reporting. Many complaints highlight difficulties with loan management, such as discrepancies in balances and interest rates, unfair or unjustified increases, and problems verifying the legitimacy of debts.'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, all the complaints included note that responses from the companies were not handled in a timely manner. Specifically, the complaint with ID 12709087 and ID 12935889 both indicate that responses were delayed beyond acceptable timeframes (\"Timely response?\": \"No\"). Additionally, the complaint with ID 13205525 about dispute settlement responses reflects that over 30 days had passed without a reply, which suggests it was also not handled promptly.\\n\\nTherefore, yes, some complaints did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, people failed to pay back their loans primarily due to various issues such as financial hardship, mismanagement by loan servicers, lack of proper communication, and misrepresentation by educational institutions. For example, one individual mentioned severe financial hardship after graduation and reliance on deferment and forbearance, which increased interest and made repayment difficult. Others experienced problems with loan servicing, such as unfair collection practices, failure to notify about payment obligations, and issues related to the legitimacy of their debts. Additionally, some borrowers faced difficulties because their educational institutions were misrepresented or had closed, leaving them unprepared for the financial consequences of their loans.\\n\\nIn summary, reasons for failure to repay included financial difficulties, lack of clear information or support from loan providers, and the impact of misrepresented or mismanaged educational ties.'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints and data, the most common issues with student loans tend to be:\\n\\n- Errors or bad information about loan balances and interest calculations\\n- Mishandling of repayment plans, including difficulty applying payments to principal\\n- Inaccurate or incorrect reporting of account status and delinquencies\\n- Confusing or inadequate communication about loan terms, transfers, or changes\\n- Problems with loan classification (e.g., FFELP vs. HEAL), misclassification, or wrongful ending of deferments\\n- Issues with loan ownership verification and validation\\n- Unexplained increases in debt due to interest or mismanagement\\n- Challenges accessing accurate loan information or documentation\\n\\nIn summary, a predominant issue appears to be mismanagement and inaccuracies in loan information, which leads to financial hardship, credit reporting errors, and confusion about loan status and repayment obligations.'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints data, yes, some complaints did not get handled in a timely manner. For example:\\n\\n- Complaint ID 12935889 against MOHELA (filed on 04/11/25) was marked as \"No\" for timely response, indicating it was not handled promptly.\\n- Complaint ID 12668396 against MOHELA (filed on 03/26/25) was also marked as \"No\" for timely response.\\n- Additionally, there are multiple complaints (such as 13062402, 13056764, 13070546) where the public response indicates the companies did not resolve the issues or respond within the expected period.\\n\\nTherefore, it appears that several complaints went unresolved or were not addressed in a timely manner.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans for various reasons, including:\\n\\n- Lack of proper notification or communication from loan servicers about payment due dates, account status changes, or loan transfers, leading to unintentional delinquency and negative impacts on credit scores.\\n- Difficulties in understanding or managing complex loan terms, interest accumulation, and eligibility for repayment plans such as income-driven repayment or loan forgiveness, often exacerbated by misinformation or insufficient guidance from servicers.\\n- Financial hardships such as unemployment, medical issues, or homelessness, which made it impossible to keep up with payments.\\n- Problems with the handling and transfer of loans, including incorrect or inconsistent reporting, unauthorized transfers, or poor recordkeeping, resulting in discrepancies and errors in credit reports.\\n- Servicers steering borrowers into long-term forbearances or alternative options that increase interest and debt over time, rather than offering sustainable repayment plans.\\n- Lack of transparency and failure to provide clear, timely information, which hinders borrowers’ ability to address their repayment obligations effectively.\\n\\nIn summary, many borrowers failed to pay their loans due to systemic issues like poor communication, mismanagement, lack of guidance, and personal financial hardships.'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(loan_complaint_data[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"Loan_Complaint_Data_Semantic_Chunks\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the complaints provided, appears to be problems related to loan servicing and communication failures. Specific issues include:\\n\\n- Difficulty in obtaining clear information about loan status, payments, and servicer changes.\\n- Errors or delays in processing payments, auto-debit setups, and re-amortization.\\n- Discrepancies in loan account status, such as loans being reported in default without borrower action.\\n- Issues with loan reporting and reporting company used reports improperly or illegally.\\n- Challenges in verifying loan authenticity or legitimacy, especially following administrative or legal changes.\\n\\nOverall, poor communication, administrative errors, and mismanagement of loan accounts are prominently featured as key issues.\\n\\nIf you have any further questions, feel free to ask!'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided complaints, yes, some complaints were not handled in a timely manner. Specifically, in the complaint regarding the transfer to Nelnet (Complaint ID: 13331376), the consumer indicated that Nelnet never responded to the certified mail complaints they sent, despite acknowledgment of receipt. The company responded by closing the complaint with an explanation, which suggests the issue was not fully resolved or addressed promptly.\\n\\nAdditionally, several complaints indicate delays or lack of proper response, but the documented responses from companies in these cases state that responses were \"Closed with explanation,\" which often implies the complaints were not handled as promptly or effectively as desired.\\n\\nTherefore, the answer is: Yes, some complaints did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The provided complaint data suggests several reasons why people failed to pay back their loans:\\n\\n1. **Miscommunication and Lack of Transparency:** Borrowers received bad information about their loans, such as incorrect forbearance statuses or payment obligations, leading to confusion and default.\\n\\n2. **Problems with Loan Servicers:** Issues like missing payments, inability to access account information, and failure to properly apply payments caused difficulties in managing repayment.\\n\\n3. **Unapproved Default or Delinquency Notices:** Borrowers reported being classified as delinquent or in default without valid reasons, sometimes due to administrative errors or misreporting.\\n\\n4. **Legal and Contractual Disputes:** Some borrowers believe their loans are illegitimate or have been wrongly reported, which affects their ability or willingness to repay.\\n\\n5. **Data Breach or Unauthorized Access:** Cases where personal information was compromised or mishandled, leading to disputes over the legitimacy of loans or fearing illegal activity related to their accounts.\\n\\n6. **Difficulty with Re-amortization or Payment Plan Changes:** When adjustments after forbearance ended were not correctly processed, resulting in higher payments and financial strain.\\n\\n7. **Disputes Over Loan Legitimacy:** Borrowers sometimes dispute the existence or legal validity of their loans due to government actions or breaches, leading to nonpayment.\\n\\nIn summary, failures to pay back loans often stem from administrative errors, miscommunication, disputes over the legitimacy or status of the loans, and issues with how payments and account information are handled by loan servicers.'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ❓ Question #3:\n",
        "\n",
        "If sentences are short and highly repetitive (e.g., FAQs), how might semantic chunking behave, and how would you adjust the algorithm?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "****\n",
        "\n",
        "Few “semantic shifts” detected -> very long chunks\n",
        "When each sentence has nearly identical embeddings (because wording and topics repeat), the similarity curve stays flat. The percentile‐based breakpoint detector may decide no point is different enough, so it merges many sentences into one oversized chunk.\n",
        "Tiny embedding distances dominated by noise\n",
        "If every sentence is only a line or two, the cosine‑distance signal that the splitter watches becomes extremely small—sometimes smaller than embedding noise—so breakpoints fluctuate unpredictably.\n",
        "Context windows wasted on duplicate information\n",
        "A chunk stuffed with 20 near‑identical FAQ lines gives the LLM less useful variety than a mixed‑topic chunk of the same length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# 🤝 Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### 🏗️ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "outputs": [],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87ac1263dde148f6914ea64406d3ed01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/14 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c2ad902f9194d828ade3f229374aec3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node e0ed1655-a61a-4501-9ba3-97901d0d4a1c does not have a summary. Skipping filtering.\n",
            "Node 717222b5-dce6-438c-947f-65231a8b72f1 does not have a summary. Skipping filtering.\n",
            "Node f2b11fa4-899b-4c61-9ab4-e69bd5730e57 does not have a summary. Skipping filtering.\n",
            "Node 5eddbbe7-753b-4ed6-9215-dfe727940962 does not have a summary. Skipping filtering.\n",
            "Node 21f46ea5-22cc-4a55-aeeb-7010aa7a9a92 does not have a summary. Skipping filtering.\n",
            "Node 90657afc-407f-40ef-bfe2-3f748adc45ff does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da26c0160cfd4312b9e9276d558a6627",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/54 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7904a182ee1a493aa8799ec59c0ef5ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying OverlapScoreBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "938a9c28f2d341a59112b188b7f70ab5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "536b6e636bcb45539ef44592ed2d1457",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14d40d21299644f98aa7834b71f8ae27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(loan_complaint_data[:20], testset_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When did the federal student loan COVID-19 for...</td>\n",
              "      <td>[The federal student loan COVID-19 forbearance...</td>\n",
              "      <td>The federal student loan COVID-19 forbearance ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wut is Aidvantge doin with my IDR aplication?</td>\n",
              "      <td>[I submitted my annual Income-Driven Repayment...</td>\n",
              "      <td>Aidvantage has not procesed my IDR aplication ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How come my info got out when FERPA supposed t...</td>\n",
              "      <td>[My personal and financial data was compromise...</td>\n",
              "      <td>My personal and financial data was compromised...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Accordng to studentaid.gov, am I suppossed to ...</td>\n",
              "      <td>[According to Studentaid.gov, Im to get an ema...</td>\n",
              "      <td>According to Studentaid.gov, you are supposed ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sinsce the resumption of fedral loan paymnts, ...</td>\n",
              "      <td>[Since the resumption of federal loan payments...</td>\n",
              "      <td>Since the resumption of federal loan payments,...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How could a privacy advocate address issues ar...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nI set up autopay with AidVantage, ...</td>\n",
              "      <td>A privacy advocate could address these issues ...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does the CFPB complaint system play a role...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nBreach of Contract - All four bran...</td>\n",
              "      <td>The CFPB (Consumer Financial Protection Bureau...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How can a borrower challenge negative credit r...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nI am devastated. I would like to r...</td>\n",
              "      <td>A borrower can challenge negative credit repor...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>how come credit bureaus and loan servicers sti...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nI am writing to formally dispute i...</td>\n",
              "      <td>credit bureaus and loan servicers still report...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>why nelnet keep reportin my student loan on cr...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nXX/XX/XXXX I increased the amount ...</td>\n",
              "      <td>nelnet still reportin your student loan on cre...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          user_input  \\\n",
              "0  When did the federal student loan COVID-19 for...   \n",
              "1      Wut is Aidvantge doin with my IDR aplication?   \n",
              "2  How come my info got out when FERPA supposed t...   \n",
              "3  Accordng to studentaid.gov, am I suppossed to ...   \n",
              "4  Sinsce the resumption of fedral loan paymnts, ...   \n",
              "5  How could a privacy advocate address issues ar...   \n",
              "6  How does the CFPB complaint system play a role...   \n",
              "7  How can a borrower challenge negative credit r...   \n",
              "8  how come credit bureaus and loan servicers sti...   \n",
              "9  why nelnet keep reportin my student loan on cr...   \n",
              "\n",
              "                                  reference_contexts  \\\n",
              "0  [The federal student loan COVID-19 forbearance...   \n",
              "1  [I submitted my annual Income-Driven Repayment...   \n",
              "2  [My personal and financial data was compromise...   \n",
              "3  [According to Studentaid.gov, Im to get an ema...   \n",
              "4  [Since the resumption of federal loan payments...   \n",
              "5  [<1-hop>\\n\\nI set up autopay with AidVantage, ...   \n",
              "6  [<1-hop>\\n\\nBreach of Contract - All four bran...   \n",
              "7  [<1-hop>\\n\\nI am devastated. I would like to r...   \n",
              "8  [<1-hop>\\n\\nI am writing to formally dispute i...   \n",
              "9  [<1-hop>\\n\\nXX/XX/XXXX I increased the amount ...   \n",
              "\n",
              "                                           reference  \\\n",
              "0  The federal student loan COVID-19 forbearance ...   \n",
              "1  Aidvantage has not procesed my IDR aplication ...   \n",
              "2  My personal and financial data was compromised...   \n",
              "3  According to Studentaid.gov, you are supposed ...   \n",
              "4  Since the resumption of federal loan payments,...   \n",
              "5  A privacy advocate could address these issues ...   \n",
              "6  The CFPB (Consumer Financial Protection Bureau...   \n",
              "7  A borrower can challenge negative credit repor...   \n",
              "8  credit bureaus and loan servicers still report...   \n",
              "9  nelnet still reportin your student loan on cre...   \n",
              "\n",
              "                       synthesizer_name  \n",
              "0  single_hop_specifc_query_synthesizer  \n",
              "1  single_hop_specifc_query_synthesizer  \n",
              "2  single_hop_specifc_query_synthesizer  \n",
              "3  single_hop_specifc_query_synthesizer  \n",
              "4  single_hop_specifc_query_synthesizer  \n",
              "5  multi_hop_specific_query_synthesizer  \n",
              "6  multi_hop_specific_query_synthesizer  \n",
              "7  multi_hop_specific_query_synthesizer  \n",
              "8  multi_hop_specific_query_synthesizer  \n",
              "9  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve(state):\n",
        "  retrieved_docs = naive_retrieval_chain.invoke(state[\"question\"])\n",
        "  return {\"context\" : retrieved_docs}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "for test_row in dataset:\n",
        "  response = naive_retrieval_chain.invoke({\"question\" : test_row.eval_sample.user_input})\n",
        "  test_row.eval_sample.response = response[\"response\"]\n",
        "  test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='The federal student loan COVID-19 forbearance program ended in 2023.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 5057, 'total_tokens': 5074, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_38343a2f8f', 'id': 'chatcmpl-BzZfSOAhBogWLx1V5bIs1QoSMNAMY', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--db855d4b-ea06-4d79-8537-63e7cd11d6a8-0', usage_metadata={'input_tokens': 5057, 'output_tokens': 17, 'total_tokens': 5074, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.samples[0].eval_sample.response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ragas.testset.synthesizers.testset_schema.Testset"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/germee/Desktop/desktop2/courses/aie7-/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [input_value=AIMessage(content='The fe...o': 0, 'reasoning': 0}}), input_type=AIMessage])\n",
            "  return self.__pydantic_serializer__.to_python(\n",
            "/Users/germee/Desktop/desktop2/courses/aie7-/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [input_value=AIMessage(content='Based ...o': 0, 'reasoning': 0}}), input_type=AIMessage])\n",
            "  return self.__pydantic_serializer__.to_python(\n",
            "/Users/germee/Desktop/desktop2/courses/aie7-/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [input_value=AIMessage(content=\"I'm so...o': 0, 'reasoning': 0}}), input_type=AIMessage])\n",
            "  return self.__pydantic_serializer__.to_python(\n",
            "/Users/germee/Desktop/desktop2/courses/aie7-/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [input_value=AIMessage(content='Accord...o': 0, 'reasoning': 0}}), input_type=AIMessage])\n",
            "  return self.__pydantic_serializer__.to_python(\n",
            "/Users/germee/Desktop/desktop2/courses/aie7-/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [input_value=AIMessage(content='The di...o': 0, 'reasoning': 0}}), input_type=AIMessage])\n",
            "  return self.__pydantic_serializer__.to_python(\n",
            "/Users/germee/Desktop/desktop2/courses/aie7-/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [input_value=AIMessage(content=\"A priv...o': 0, 'reasoning': 0}}), input_type=AIMessage])\n",
            "  return self.__pydantic_serializer__.to_python(\n",
            "/Users/germee/Desktop/desktop2/courses/aie7-/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [input_value=AIMessage(content='The CF...o': 0, 'reasoning': 0}}), input_type=AIMessage])\n",
            "  return self.__pydantic_serializer__.to_python(\n",
            "/Users/germee/Desktop/desktop2/courses/aie7-/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [input_value=AIMessage(content=\"To cha...o': 0, 'reasoning': 0}}), input_type=AIMessage])\n",
            "  return self.__pydantic_serializer__.to_python(\n",
            "/Users/germee/Desktop/desktop2/courses/aie7-/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [input_value=AIMessage(content='After ...o': 0, 'reasoning': 0}}), input_type=AIMessage])\n",
            "  return self.__pydantic_serializer__.to_python(\n",
            "/Users/germee/Desktop/desktop2/courses/aie7-/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [input_value=AIMessage(content=\"Based ...o': 0, 'reasoning': 0}}), input_type=AIMessage])\n",
            "  return self.__pydantic_serializer__.to_python(\n"
          ]
        }
      ],
      "source": [
        "from ragas import EvaluationDataset\n",
        "\n",
        "evaluation_dataset = dataset.to_pandas()\n",
        "evaluation_dataset[\"response\"] = evaluation_dataset[\"response\"].apply(lambda r: r[\"content\"] if isinstance(r, dict) and \"content\" in r else r)\n",
        "evaluation_dataset = EvaluationDataset.from_pandas(evaluation_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "144749c5b3f744f1aaccee872541edf5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[35]: TimeoutError()\n",
            "Exception raised in Job[41]: TimeoutError()\n",
            "Exception raised in Job[47]: TimeoutError()\n",
            "Exception raised in Job[53]: TimeoutError()\n",
            "Exception raised in Job[59]: TimeoutError()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'context_recall': 0.8552, 'faithfulness': 0.7755, 'factual_correctness': 0.4380, 'answer_relevancy': 0.7605, 'context_entity_recall': 0.5372, 'noise_sensitivity_relevant': 0.3813}\n",
            "📊 Performance metrics: {'context_recall': 0.8552, 'faithfulness': 0.7755, 'factual_correctness': 0.4380, 'answer_relevancy': 0.7605, 'context_entity_recall': 0.5372, 'noise_sensitivity_relevant': 0.3813}\n",
            "⏱️  Total latency: 434.22 seconds\n",
            "📈 Token usage: not available for gpt-4.1-mini\n",
            "💰 Estimated cost: manually estimate based on number of samples × avg token usage\n"
          ]
        }
      ],
      "source": [
        "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
        "from ragas import evaluate, RunConfig\n",
        "import time\n",
        "\n",
        "custom_run_config = RunConfig(timeout=360)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "result = evaluate(\n",
        "    dataset=evaluation_dataset,\n",
        "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
        "    llm=evaluator_llm,\n",
        "    run_config=custom_run_config\n",
        ")\n",
        "print(result)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(\"📊 Performance metrics:\", result)\n",
        "print(\"⏱️ Total latency:\", round(end - start, 2), \"seconds\")\n",
        "print(\"📈 Token usage: not available for gpt-4.1-mini\")\n",
        "print(\"💰 Estimated cost: manually estimate based on number of samples × avg token usage\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "naive_retrieval\n",
        "\n",
        "{'context_recall': 0.8567, 'faithfulness': 0.7587, 'factual_correctness': 0.6400, 'answer_relevancy': 0.4831, 'context_entity_recall': 0.4300, 'noise_sensitivity_relevant': 0.2911}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install -qU langchain-community==0.3.14 langchain-openai==0.3.7 unstructured==0.16.12 langgraph==0.2.61 langchain-qdrant==0.2.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"NAIVE2 - {uuid4().hex[0:8]}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "\n",
        "eval_llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "\n",
        "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : eval_llm})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'SingleTurnSample' object has no attribute 'dataset_id'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[96]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnaive_retrieval_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrevision_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mempathy_rag_chain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/desktop2/courses/aie7-/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py:423\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling, **kwargs)\u001b[39m\n\u001b[32m    421\u001b[39m     _warn_once(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mupload_results\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter is in beta.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    422\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning evaluation over target system \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mEVALUATOR_T\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/desktop2/courses/aie7-/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py:1064\u001b[39m, in \u001b[36m_evaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling)\u001b[39m\n\u001b[32m   1048\u001b[39m runs = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m _is_callable(target) \u001b[38;5;28;01melse\u001b[39;00m cast(Iterable[schemas.Run], target)\n\u001b[32m   1049\u001b[39m experiment_, runs = _resolve_experiment(experiment, runs, client)\n\u001b[32m   1051\u001b[39m manager = \u001b[43m_ExperimentManager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If provided, we don't need to create a new experiment.\u001b[39;49;00m\n\u001b[32m   1059\u001b[39m \u001b[43m    \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Create or resolve the experiment.\u001b[39;49;00m\n\u001b[32m   1061\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_attachments\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_include_attachments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_dir := ls_utils.get_cache_dir(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1066\u001b[39m     cache_path = pathlib.Path(cache_dir) / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmanager.dataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.yaml\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/desktop2/courses/aie7-/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py:1439\u001b[39m, in \u001b[36m_ExperimentManager.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1437\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _ExperimentManager:\n\u001b[32m   1438\u001b[39m     first_example = \u001b[38;5;28mnext\u001b[39m(itertools.islice(\u001b[38;5;28mself\u001b[39m.examples, \u001b[32m1\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m1439\u001b[39m     project = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_example\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._upload_results \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1440\u001b[39m     \u001b[38;5;28mself\u001b[39m._print_experiment_start(project, first_example)\n\u001b[32m   1441\u001b[39m     \u001b[38;5;28mself\u001b[39m._metadata[\u001b[33m\"\u001b[39m\u001b[33mnum_repetitions\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._num_repetitions\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/desktop2/courses/aie7-/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py:1248\u001b[39m, in \u001b[36m_ExperimentManagerMixin._get_project\u001b[39m\u001b[34m(self, first_example)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1246\u001b[39m     project_metadata = \u001b[38;5;28mself\u001b[39m._get_experiment_metadata()\n\u001b[32m   1247\u001b[39m     project = \u001b[38;5;28mself\u001b[39m._create_experiment(\n\u001b[32m-> \u001b[39m\u001b[32m1248\u001b[39m         \u001b[43mfirst_example\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_id\u001b[49m, project_metadata\n\u001b[32m   1249\u001b[39m     )\n\u001b[32m   1250\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1251\u001b[39m     project = \u001b[38;5;28mself\u001b[39m._experiment\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/desktop2/courses/aie7-/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/pydantic/main.py:991\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mAttributeError\u001b[39m: 'SingleTurnSample' object has no attribute 'dataset_id'"
          ]
        }
      ],
      "source": [
        "evaluate(\n",
        "    naive_retrieval_chain.invoke,\n",
        "    data=evaluation_dataset,\n",
        "    evaluators=[\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"empathy_rag_chain\"},\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
